{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.strings import regex_replace\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Using text_dataset_from_directory tool (https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text_dataset_from_directory)\n",
    "dir = \"DATA/movie-reviews-dataset\"\n",
    "train_data = text_dataset_from_directory(dir+\"/train\")\n",
    "test_data = text_dataset_from_directory(dir+\"/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"I rented this movie last week. I saw Kevin Spacey and Morgan Freeman were on it, so it seemed promising. And it was, until Justin Timberlake came on scene. He is a really bad actor and shouldn't be allowed to make a movie ever again. I mean, he is one of the most boring, uninspired actors I've ever seen. He puts absolutely no emotion to any of his lines whatsoever. Why the hell was he cast for the role of Josh Pollack? I think Matt Damon would have been a better choice.<br /><br />Kevin Spacey was another big disappointment. His character is so dull, it seems like a bad mix of his character in American Beauty and John Doe in Se7en. It might sound cool, but believe me, it's not.<br /><br />Now, Dylan McDermott's acting is very good. It's about one of the very few good things about this movie. He is just inspired.<br /><br />Morgan Freeman is good but nothing special. He has some really cool lines though.<br /><br />About the story, although it was a bit obvious and exaggerated at times it was good. I was expecting a big twist when Lazerov (Dylan McDermott) was killed, but nothing really happened.\"\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Let's take a look at some data\n",
    "for text_batch, label_batch in train_data.take(1):\n",
    "  print(text_batch.numpy()[1])\n",
    "  print(label_batch.numpy()[1]) # 0 = negative, 1 = positive\n",
    "# we need to remove the <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the data (html)\n",
    "def prepareData(dir):\n",
    "  data = text_dataset_from_directory(dir)\n",
    "  return data.map(\n",
    "    lambda text, label: (regex_replace(text, '<br />', ' '), label),\n",
    "  )\n",
    "\n",
    "train_data = prepareData(dir+'/train')\n",
    "test_data = prepareData(dir+'/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "# input layer (1 string):\n",
    "model.add(Input(shape=(1,), dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization\n",
    "# The first layer processes the input string and turns it into a sequence of\n",
    "# max_len integers, each of which maps to a certain token.\n",
    "# It will automatically lowercases text, splits on whitespace and strips punctuation (when calling adapt()).\n",
    "\n",
    "max_features = 1000\n",
    "# We set a limit to 1000 tokens (i.e. the size of our vocabulary).\n",
    "# Any word outside the vocabulary will be treated as OOV (\"out of vocabulary\") token which is counted inside the 1000.\n",
    "# Note on max_features: a value too low will exclude potentially useful words from our vocabulary, while\n",
    "# a value too high may increase the complexity and training time of our model.\n",
    "\n",
    "max_len = 100\n",
    "# Note on max_len: a value too low of a max_len will impact our modelâ€™s performance on longer reviews, while\n",
    "# again a value too high may increase the complexity and training time of our model.\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "  max_tokens=max_features,\n",
    "  output_mode=\"int\",\n",
    "  # Always pad or truncate to exactly this many tokens\n",
    "  output_sequence_length=max_len,\n",
    ")\n",
    "\n",
    "# Call adapt(), which fits the TextVectorization layer to our text dataset.\n",
    "# This is when the max_tokens most common words (i.e. the vocabulary) are selected.\n",
    "train_texts = train_data.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(train_texts)\n",
    "\n",
    "model.add(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "# This layer turns each integer (representing a token) from the previous layer\n",
    "# into dense vectors of fixed siwe. \n",
    "# Note that we're using max_tokens + 1 here, since there's an\n",
    "# OOV token that gets added to the vocab.\n",
    "model.add(Embedding(max_features + 1, 128))\n",
    "\n",
    "# Recurrent layer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
    "# note: 64 is the dimensionality of the output space (i.e. units)\n",
    "model.add(LSTM(64))\n",
    "\n",
    "# Standard fully connected dense hidden layer\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "# Output\n",
    "# sigmoid is a perfect activation function because it outputs a number between 0 (bad review) and 1 (good review)\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization_5 (TextVe (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 100, 128)          128128    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 181,761\n",
      "Trainable params: 181,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.5450 - accuracy: 0.7099\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 82s 105ms/step - loss: 0.4330 - accuracy: 0.8009\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 81s 104ms/step - loss: 0.4099 - accuracy: 0.8124\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.3812 - accuracy: 0.8291\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 78s 99ms/step - loss: 0.3689 - accuracy: 0.8361\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.3481 - accuracy: 0.8478\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 77s 99ms/step - loss: 0.3333 - accuracy: 0.8565\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.3213 - accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 77s 98ms/step - loss: 0.3185 - accuracy: 0.8624\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.3020 - accuracy: 0.8714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3b895a90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling and training the model.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_data, epochs=10)\n",
    "# (my laptop is quite old...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97839177]]\n",
      "[[0.01224911]]\n",
      "Ambiguous reviews\n",
      "1 [[0.54231006]]\n",
      "1 worse [[0.01726171]]\n",
      "1 better [[0.54523134]]\n",
      "2 [[0.05067167]]\n",
      "2 reversed [[0.93946326]]\n",
      "3 [[0.03092992]]\n",
      "Non-sense\n",
      "4 [[0.14377838]]\n",
      "5 [[0.5409306]]\n",
      "6 [[0.5390476]]\n",
      "7 [[0.538474]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "\n",
    "print(model.predict([\n",
    "  \"i loved this movie ! It was really amazing\",\n",
    "])) # it should be close to 1\n",
    "print(model.predict([\n",
    "  \"a very bad movie ! Save your money\",\n",
    "])) # it should be close to 0\n",
    "\n",
    "# Let's be nasty...\n",
    "print(\"Ambiguous reviews\")\n",
    "print(\"1\", model.predict([\n",
    "  \"The acting was extremely good but the photography and music were meh\",\n",
    "])) \n",
    "print(\"1 worse\", model.predict([\n",
    "  \"The acting was extremely good but the photography and music were bad\",\n",
    "])) \n",
    "print(\"1 better\", model.predict([\n",
    "  \"The acting was extremely good but the photography and music were on the average\",\n",
    "])) \n",
    "print(\"2\", model.predict([\n",
    "  \"An amazing cast and music but the plot was really obvious !\",\n",
    "])) \n",
    "print(\"2 reversed\", model.predict([\n",
    "  \"The plot was really obvious but an amazing cast and music !\",\n",
    "])) \n",
    "print(\"3\", model.predict([\n",
    "  \"I don't know if it was good or bad...\",\n",
    "]))\n",
    "print(\"Non-sense\")\n",
    "print(\"4\", model.predict([\n",
    "  \"Great bad movie !\",\n",
    "])) \n",
    "print(\"5\", model.predict([\n",
    "  \"I love pinapples !\",\n",
    "])) \n",
    "print(\"6\", model.predict([\n",
    "  \"I hate pears !\",\n",
    "])) \n",
    "print(\"7\", model.predict([\n",
    "  \"The cat is under the table\",\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
